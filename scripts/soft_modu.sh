export num_envs=50
PYTHONPATH=. python -u ../main.py \
setup=metaworld \
setup.algo=soft_mt${num_envs} \
env=metaworld-mt${num_envs} \
agent=state_sac \
experiment.num_eval_episodes=1 \
experiment.num_train_steps=2500000 \
experiment.random_pos=False \
setup.seed=$1 \
setup.dir_name=logs_fix \
replay_buffer.batch_size=6400 \
agent.multitask.num_envs=${num_envs} \
agent.multitask.should_use_disentangled_alpha=True \
agent.multitask.should_use_task_encoder=True \
agent.encoder.type_to_select=feedforward \
agent.multitask.actor_cfg.should_condition_model_on_task_info=True \
agent.multitask.actor_cfg.should_condition_encoder_on_task_info=False \
agent.multitask.actor_cfg.should_concatenate_task_info_with_encoder=False \
agent.multitask.actor_cfg.moe_cfg.should_use=True \
agent.multitask.actor_cfg.moe_cfg.mode=soft_modularization \
agent.multitask.should_use_multi_head_policy=False \
agent.encoder.feedforward.hidden_dim=64 \
agent.encoder.feedforward.num_layers=2 \
agent.encoder.feedforward.feature_dim=64 \
agent.actor.num_layers=4 \
agent.multitask.task_encoder_cfg.model_cfg.pretrained_embedding_cfg.should_use=True